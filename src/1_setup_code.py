# -*- coding: utf-8 -*-
"""1_Setup_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YfZV3xL5Fcc2nU471me-v0FbLd6AjBMI
"""

# Commented out IPython magic to ensure Python compatibility.
#Establish the link between Colab and github repositary
!git clone https://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@github.com/hhashem4/arabic-abstracts-analysis.git
# %cd arabic-abstracts-analysis

"""# New Section"""

# Create the directories
!mkdir -p data notebooks src models reports docs

# Create .gitkeep files inside each
!touch data/.gitkeep
!touch notebooks/.gitkeep
!touch src/.gitkeep
!touch models/.gitkeep
!touch reports/.gitkeep
!touch docs/.gitkeep

!git config --global user.email "https://github.com/hhashem4/arabic-abstracts-analysis.git"
!git config --global user.name "hhashem4"

# Remove any old remote
!git remote remove origin

# Add new remote with username + token

!git remote add origin https://hhashem4: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@github.com/hhashem4/arabic-abstracts-analysis.git

# Add all new files (including the .gitkeep files)
!git add .

# Commit the changes
!git commit -m "Add initial project folders: data, reports, docs, src"

# Push the changes to GitHub
!git push origin main # Or your default branch, e.g., 'master'

# =======================
# Import the required libraries
# =======================
from datasets import load_dataset
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# =======================
# Load the dataset from KFUPM-JRCAI into Colab
# =======================
dataset = load_dataset("KFUPM-JRCAI/arabic-generated-abstracts")

print("Available splits / subsets:")
print(dataset)

# Example: explore by_polishing split
sample = dataset["by_polishing"][0]
print("Original:", sample["original_abstract"])
print("ALLaM:", sample["allam_generated_abstract"])

# =======================
# Convert the dataset to Pandas dataframe
# =======================
df_polish = pd.DataFrame(dataset["by_polishing"])
df_title = pd.DataFrame(dataset["from_title"])
df_title_content = pd.DataFrame(dataset["from_title_and_content"])

print("\n[INFO] Columns in by_polishing dataset:")
print(df_polish.columns)

df_polish

# Save the dataframe into a CSV file
df_polish.to_csv("/content/arabic-abstracts-analysis/data/by_polishing.csv", index=False)

# Mount the files in content/drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Store the CSV file in github repository
!git config user.name "hhashem4"
!git config user.email "hhashem489@gmail.com"
!git checkout main

# %cd /content/arabic-abstracts-analysis
!git add data/by_polishing.csv
!git commit -m "Added by_polishing.csv dataset"
!git push origin main